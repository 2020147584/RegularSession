{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CVdSNimTlZjX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RfvVn2NulZjf"
      },
      "outputs": [],
      "source": [
        "# Prepare dataset\n",
        "data = np.loadtxt('data.csv', delimiter=',', dtype=float)\n",
        "labels = data[:, 0]\n",
        "features = preprocessing.minmax_scale(data[:, 1:])\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels.ravel(), test_size=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ0WmEKElZjh"
      },
      "source": [
        "### 의사결정나무\n",
        "* random_state = 2022 으로 설정\n",
        "* 변수명은 dt_clf 로 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XOUS-C46lZjn"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Z1RCZCrSlZjo"
      },
      "outputs": [],
      "source": [
        "# 빈 부분 코드 작성\n",
        "# decision tree\n",
        "dt_clf = DecisionTreeClassifier(random_state=2022)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBgp0SAQlZjq",
        "outputId": "38fbd89a-96a7-45b2-e0f8-41e58ee9ae54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(random_state=2022)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# 개별 분류기에 train set 피팅\n",
        "dt_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D5BBWXTplZjs"
      },
      "outputs": [],
      "source": [
        "# test셋으로 prediction\n",
        "dt_pred = dt_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM3JMON0lZju",
        "outputId": "4b68ccb7-c7cd-4003-ccd2-c5b3be96c6ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "의사결정나무 정확도: 0.8713\n"
          ]
        }
      ],
      "source": [
        "# 성능 확인\n",
        "# accuracy_score 계산\n",
        "accuracy=accuracy_score(y_test, dt_pred)\n",
        "print('의사결정나무 정확도: {0:.4f}'.format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aAokdYAlZjv"
      },
      "source": [
        "### 랜덤 포레스트\n",
        "* random_state = 2022\n",
        "* 변수명 rf_clf 로"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "d0C0QDbnlZjx"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BN5Upvb4lZjy"
      },
      "outputs": [],
      "source": [
        "# random forest\n",
        "rf_clf = RandomForestClassifier(random_state=2022)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ-EiueflZjz",
        "outputId": "b75ee7e7-9689-4aca-e65e-2d042aea1014"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=2022)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# 개별 분류기에 train set 피팅\n",
        "rf_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4pwHpIv9lZjz"
      },
      "outputs": [],
      "source": [
        "# test셋으로 prediction\n",
        "rf_pred = rf_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e87IcfQ1lZj0",
        "outputId": "dbf9f924-5ae2-4f03-bc5b-2c991b6ec19b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "랜덤포레스트 정확도: 0.9406\n"
          ]
        }
      ],
      "source": [
        "# 성능 확인\n",
        "# accuracy_score 계산\n",
        "accuracy=accuracy_score(y_test, rf_pred)\n",
        "print('랜덤포레스트 정확도: {0:.4f}'.format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dreJrmFklZj1"
      },
      "source": [
        "### Gradient Boost\n",
        "* random_state = 2022\n",
        "* 변수명 gb_clf 로"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FmxE83FqlZj2"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "23Y4SC2blZj2"
      },
      "outputs": [],
      "source": [
        "# gradient boost\n",
        "gb_clf = GradientBoostingClassifier(random_state=2022)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnBCEy9QlZj3",
        "outputId": "a8ed4ef7-6466-43de-bf9c-3be380f0ec1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(random_state=2022)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# 개별 분류기에 train set 피팅\n",
        "gb_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1kNAVrzHlZj3"
      },
      "outputs": [],
      "source": [
        "# test셋으로 prediction\n",
        "gb_pred =gb_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ema38SQlZj4",
        "outputId": "9b6d04aa-d411-494c-bbe8-d15caa079a91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boost 정확도: 0.9505\n"
          ]
        }
      ],
      "source": [
        "# 성능 확인\n",
        "# accuracy_score 계산\n",
        "accuracy=accuracy_score(y_test, gb_pred)\n",
        "print('Gradient Boost 정확도: {0:.4f}'.format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgRWGprSlZj5"
      },
      "source": [
        "### 보고서 과제\n",
        "1. voting, bagging, random forest, boosting, adaboost, gradient boost 의 특징 및 장단점을 스스로 정리해보기\n",
        "2. Boosting의 advanced model 인 XGBoost, LightGBM, CatBoost에 대해 찾아보고 정리해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## *1.*\n",
        "1. **Voting**  \n",
        "여러개의 서로 다른 알고리즘을 가진 분류기로 나누어 같은 데이터셋을 학습한 후, 결과물을 조합하여 최종 투표하는 방식이다. 다수의 분류기가 예측한 결과값으로 최종결과값을 선정하는 Hard voting과, 모든 분류기가 예측한 확률값을 평균내어,가장 확률이 높은 값으로 선정하는 Soft voting으로 나뉘며 주로, 합리적인 Soft voting을 사용한다.\n",
        "\n",
        "2. **Bagging**  \n",
        "같은 알고리즘 유형의 모델들로 학습하지만, 데이터 샘플링(복원추출)을 다르게 해서 학습 데이터셋이 각각 다르고, 결과물을 조합하여 최종 투표하는 방식이다.\n",
        "*   장점: 단일 model을 활용했을 때보다 Variance를 줄일 수 있다. Overfitting 방지를 할 수 있다.\n",
        "\n",
        "3. **Random forest**  \n",
        "의사결정나무를 이용한 대표적인 Bagging 방식으로, 앙상블의 다양성을 추가로 확보하기 위해 변수의 임의 추출 방식을 사용한다. \n",
        "*   변수의 임의 추출: **변수**의 임의 추출을 통해 tree의 다양성을 확보할 수 있다. 변수 임의 추출을 하게 되면 변수 중복이 줄어 개별 모형들 사이의 상관관계가 줄어들기 때문에 모형 성능의 변동이 감소하여 안정성을 갖추게 되는 효과가 있다.\n",
        "> 변수를 임의 추출하기 때문에, 포레스트 안에서 information gain을 비교함으로써, 어떤 독립변수가 중요한지 간접적인 방식으로 변수중요도를 비교하고 해석할 수 있다.\n",
        "\n",
        "4. **Boosting**  \n",
        "여러개의 분류기가 순차적으로 학습을 수행하며, 이전 학습에서 잘못 예측된 데이터에 가중치를 부여해 오차를 보완해 나가는 방식이다.\n",
        "*   장점: 더 예측이 어려운 관찰치 혹은 영역을 반복적으로 학습가능, 지속적 반복학습을 통해 이 영역에 더 정확한 예측 가능, 각 반복학습을 통합해 최종예측 수행\n",
        "*   단점: 순차적알고리즘으로 병렬처리에 어려움이 있어, 학습시간이 다른 앙상블기법에 비해 오래걸린다. \n",
        "\n",
        "5. **Adaboost**  \n",
        "가중치를 부여한 약 분류기를 모아서 최종적인 강분류기를 생성하는 기법\n",
        "(1명의 천재< 10명의 평범한 사람)\n",
        "* 특징: 랜덤포레스트와는 달리, 특정 분류기가 다른 분류기보다 더 중요한것을 고려하여 가중치를 차별하여 부여(분류기 별 가중치 차별화)\n",
        "> 오분류된 데이터에 가중치 높게 설정\n",
        "\n",
        "6. **Gradient boost**  \n",
        "약분류기들을 결합한 강분류기를 사용하는 것은 동일 Residual Fitting이 특징이다. (잔차를 예측하는 방식)-> 그렇기 때문에 overfitting위험이 있음.\n",
        "---\n",
        "## *2.*\n",
        "1. **XGBoost**  \n",
        " GBM은 잔여오차를 줄이는 방법으로 약한 학습기를 결합해서 높은 성능을 보이는 반면, 훈련데이터의 잔여오차를 계속해서 줄이기 때문에 과적합이 발생되기 쉽다. XGBoost는 GBM의 이러한 단점을 보완하여 높은 예측성능을 보이며 속도도 빠르게 수행하는 알고리즘이다. XGBoost는 병렬처리를 통해 빠른 학습을 하고, learning system이 유연하다. 또한, overfitting방지를 위한 설계가 되어있으며 다양한 시나리오에 대한 확장성을 가지고 있는 것이 특징이자 장점이다. \n",
        "\n",
        "2. **LightGBM**  \n",
        "LightGBM은 대부분의 트리가 균형을 맞추며 분할하는 반면, 트리의 균형을 맞추지 않고, ’Leaf-wise(리프 중심)’로 분할되며 트리가 비대칭적인(균형 유지X) 트리를 생성하며(수직적으로 확장)커져서 예측 오류 손실을 최소화한다.\n",
        "\n",
        "3. **CatBoost**  \n",
        "XGBoost 와 더불어 Catboost 는 Level-wise 로 트리를 만들어나간다. 순열 기반의 대안인 ordered boosting이 특징이며, 범주형 피처처리를 위한 알고리즘이 도입됐다. 단점으로는 Sparse 한 Matrix 는 처리하지 못한다. 데이터 대부분이 수치형 변수인 경우, Light GBM 보다 학습 속도가 느리다. 속도측면에서 범주형변수에 사용하는게 적합하다.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fntmqESPp2yz"
      }
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "[6기 조수연] Ensemble 과제.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}