{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "data = np.loadtxt('data.csv', delimiter=',', dtype=float)\n",
    "labels = data[:, 0]\n",
    "features = preprocessing.minmax_scale(data[:, 1:])\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels.ravel(), test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 의사결정나무\n",
    "* random_state = 2022 으로 설정\n",
    "* 변수명은 dt_clf 로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 부분 코드 작성\n",
    "# decision tree\n",
    "dt_clf = DecisionTreeClassifier(random_state = 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 분류기에 train set 피팅\n",
    "dt_clf = dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test셋으로 prediction\n",
    "dt_pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8514851485148515\n"
     ]
    }
   ],
   "source": [
    "# 성능 확인\n",
    "# accuracy_score 계산\n",
    "print(accuracy_score(dt_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜덤 포레스트\n",
    "* random_state = 2022\n",
    "* 변수명 rf_clf 로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "rf_clf = RandomForestClassifier(random_state = 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 분류기에 train set 피팅\n",
    "rf_clf = rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test셋으로 prediction\n",
    "rf_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9801980198019802\n"
     ]
    }
   ],
   "source": [
    "# 성능 확인\n",
    "# accuracy_score 계산\n",
    "print(accuracy_score(rf_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost\n",
    "* random_state = 2022\n",
    "* 변수명 gb_clf 로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boost\n",
    "gb_clf = GradientBoostingClassifier(random_state = 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 분류기에 train set 피팅\n",
    "gb_clf = gb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test셋으로 prediction\n",
    "gb_pred = gb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9801980198019802\n"
     ]
    }
   ],
   "source": [
    "# 성능 확인\n",
    "# accuracy_score 계산\n",
    "print(accuracy_score(gb_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 보고서 과제\n",
    "1. voting, bagging, random forest, boosting, adaboost, gradient boost 의 특징 및 장단점을 스스로 정리해보기\n",
    "2. Boosting의 advanced model 인 XGBoost, LightGBM, CatBoost에 대해 찾아보고 정리해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. voting<br>\n",
    "서로 다른 알고리즘으로 구성된 여러 개의 분류기가 도출해낸 결과물을 조합하여 투표하는 방식\n",
    "단일 모델만을 활용하여 예측했을 때보다 분산을 줄이는 효과를 볼 수 있으며 과적합 방지에 효과적\n",
    "다양성을 보장받을 수 있으나 각 모델 별 알고리즘 구성 시 결과가 편향될 수도 있기에 성격이 다른 모델들이 되도록 구성 필요<br><br>\n",
    "\n",
    "2. bagging<br>\n",
    "서로 다른 데이터 샘플을 여러 번 뽑아 각 모델을 같은 알고리즘으로 학습시켜 결과물을 집계하는 방식\n",
    "단일 모델만을 활용하여 예측했을 때보다 분산을 줄이는 효과를 볼 수 있으며 과적합 방지에 효과적\n",
    "샘플을 랜덤으로 추출하여 반복하기에 예측력은 높으나 해석력은 미약<br><br>\n",
    "\n",
    "3. random forest<br>\n",
    "데이터의 모든 변수를 임의로 추출하여 랜덤으로 모델들을 생성한 후 결과물을 집계하는 방식\n",
    "단일 모델만을 활용하여 예측했을 때보다 분산을 줄이는 효과를 볼 수 있으며 과적합 방지에 효과적\n",
    "변수들의 중요도를 판단할 수 있어 해석력이 올라감<br><br>\n",
    "\n",
    "4. boosting<br>\n",
    "여러 개의 분류기가 이전 학습에서 잘못 예측된 데이터에 가중치를 부여해 오차를 보완해 나가는 순차적 방식으로 학습 수행 \n",
    "더 예측이 어려운 관찰치 혹은 영역을 반복적으로 학습하고 지속적 반복학습을 통해 이 영역에 더 정확한 예측이 가능\n",
    "마지막에 각 반복학습의 결과를 통합하여 최종 예측을 수행함\n",
    "순차적이므로 병렬 처리에 어려움 있고 다른 앙상블 대비 학습 시간이 오래 걸리는 단점 존재<br><br>\n",
    "\n",
    "5. adaboost<br>\n",
    "Adaboost는 편향과 분산을 모두 줄이는 부스팅 방법으로 가중치를 부여한 약 분류기를 모아 최종적인 강 분류기를 생성하는 방식으로 동작\n",
    "가중치를 임의로 부여하기에 효율적이지 못하다는 단점 존재\n",
    "<br><br>\n",
    "\n",
    "6. gradient boost<br>\n",
    "Adaboost의 기본 idea와 동일아나 가중치를 update할 때 Gradient Descent Algorithm을 이용하여 최적 weight을 계산함으로써 adaboost의 단점을 보완한 알고리즘\n",
    "단, 오차 계산과 잔차 피팅이 계속 이뤄지며 이를 토대로 모델이 개선되기 때문에 느린 속도와 과적합 문제가 단점으로 작용\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. XGBoost<br>\n",
    "Ensemble Boosting model들의 단점들을 보완하기 위해 탄생\n",
    "그 중에서도 특히 Gradient boosting 모델의 순차적인 계산으로 인한 느린 속도, 잔차를 계속 줄임으로써 과적합 발생과 같은 단점을 보완\n",
    "보완하는 방법으로는 느린 속도 문제점을 직렬식(순차적) 수행이 아닌 병렬식 수행으로 보완, 과적합 발생 문제점을 과도한 학습이 이뤄지지 않도록 정규화 식을 추가해 모델 복잡도가 상승할수록 손실값에 페널티를 부여하는 방식 구현으로 보완이 존재\n",
    "이 외에도 결측치를 내부적으로 처리하여 정확도 상승, 가지치기를 통해 분할 수를 축소하여 효율적 분석, 조기 중단과 같은 특징이 존재<br><br>\n",
    "\n",
    "2. LightGBM<br>\n",
    "Boosting의 단점을 보완한 XGBoost의 성능을 향상시키기 위해 탄생\n",
    "XGBoost에서 병렬식 수행으로 속도 문제점을 어느정도 보완하였으나 여전히 긴 학습 시간이라는 단점 존재\n",
    "보완하는 방법으로는 기존 트리 분할 방식을 리프 중심의 분할 방식을 채택함으로써 보완이 존재\n",
    "기존에는 모든 depth가 동일하다는 가정하에 모든 node를 분할하여 균형 잡힌 형태의 트리를 생성하나 LightGBM은 상대적으로 분할이 더 필요한 node(손실이 큰 트리)에 대해서만 분할이 이뤄져 보다 효율적\n",
    "깊이가 깊어져 과적합이 발생할 수도 있기에 max-depth 파라미터를 설정하여 조절이 필요<br><br>\n",
    "\n",
    "3. CatBoost<br>\n",
    "기존의 부스팅 알고리즘들의 동작 시간이 오래 걸리며 hyper-parameter 튜닝에 민감하여 다루기 번거롭다는 단점을 보완하기 위해 탄생\n",
    "또한 기존의 알고리즘들은 이전 데이터를 반복적으로 쓰는 과정에서 발생하는 target leakage 문제와 예측 결과변화 문제, 범주형 변수를 수치형 변수로 전처리를 해준 후 일일이 훈련을 해줘야 한다는 문제를 가지고 있기에 CatBoost는 이 세 가지 문제를 각각 Ordered boosting과, 새로운 범주형 변수 처리 방법으로 해결\n",
    "CatBoost는 최적화가 잘 되어 있기에 파라미터 튜닝에 큰 신경을 쓰지 않아도 되며, 학습 속도도 상대적으로 빠름으로써 단점을 보완하였으나 Sparse 한 Matrix 는 처리하지 못한다는 점과 데이터 대부분이 수치형 변수인 경우, Light GBM 보다도 학습 속도가 느리다는 점이 존재\n",
    "따라서 가급적 대부분이 범주형 변수인 경우 사용\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
