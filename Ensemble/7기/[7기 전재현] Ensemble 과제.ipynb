{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "data = np.loadtxt('data.csv', delimiter=',', dtype=float)\n",
    "labels = data[:, 0]\n",
    "features = preprocessing.minmax_scale(data[:, 1:])\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels.ravel(), test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 의사결정나무\n",
    "* random_state = 2022 으로 설정\n",
    "* 변수명은 dt_clf 로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 부분 코드 작성\n",
    "# decision tree\n",
    "dt_clf = DecisionTreeClassifier(random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=2022)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개별 분류기에 train set 피팅\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test셋으로 prediction\n",
    "dt_pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy : 0.9208\n"
     ]
    }
   ],
   "source": [
    "# 성능 확인\n",
    "# accuracy_score 계산\n",
    "\n",
    "acc1 = accuracy_score(y_test,dt_pred)\n",
    "print(\"Decision Tree Accuracy : {0:.4}\".format(acc1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 랜덤 포레스트\n",
    "* random_state = 2022\n",
    "* 변수명 rf_clf 로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "rf_clf = RandomForestClassifier(random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=2022)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개별 분류기에 train set 피팅\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test셋으로 prediction\n",
    "rf_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy : 0.9604\n"
     ]
    }
   ],
   "source": [
    "# 성능 확인\n",
    "# accuracy_score 계산\n",
    "\n",
    "acc2 = accuracy_score(y_test,rf_pred)\n",
    "print(\"Random Forest Accuracy : {0:.4}\".format(acc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost\n",
    "* random_state = 2022\n",
    "* 변수명 gb_clf 로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boost\n",
    "gb_clf = GradientBoostingClassifier(random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=2022)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개별 분류기에 train set 피팅\n",
    "gb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test셋으로 prediction\n",
    "gb_pred = gb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost Accuracy : 0.9406\n"
     ]
    }
   ],
   "source": [
    "# 성능 확인\n",
    "# accuracy_score 계산\n",
    "\n",
    "acc3 = accuracy_score(y_test,gb_pred)\n",
    "print(\"Gradient Boost Accuracy : {0:.4}\".format(acc3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 보고서 과제\n",
    "1. voting, bagging, random forest, boosting, adaboost, gradient boost 의 특징 및 장단점을 스스로 정리해보기\n",
    "2. Boosting의 advanced model 인 XGBoost, LightGBM, CatBoost에 대해 찾아보고 정리해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Voting\n",
    "\n",
    "- 하나의 데이터셋에 대해 여러 개의 분류기가 결과물을 도출하고 이를 조합해 최종 투표하는 방식이다.\n",
    "- Hard Voting은 분류기가 예측한 결과값 중 다수가 나온 것을 최종 결과로 선정\n",
    "- Soft Voting은 분류기가 예측한 값의 확률을 평균 내어 가장 높게 나온 것을 최종 결과로 선정 (Hard보다 더 합리적)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bagging\n",
    "- Voting처럼 단일 데이터셋이 아닌 데이터 샘플을 여러 번 복원추출\n",
    "- 각 샘플에 대해 모델 학습시켜 결과물 집계\n",
    "\n",
    "장점) 단일 model 활용보다 Variance 줄일 수 있어 Overfitting 방지에 효과적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1. Random Forest\n",
    "- Decision Tree 활용한 Bagging\n",
    "- 변수의 임의추출을 통해 모든 변수를 보고 분할하는 Decison Tree들의 다양성 확보\n",
    "- 개별 데이터셋 구성 시 추출되지 않은 데이터 Test로 사용 (Out of Bag)\n",
    "- 간접적으로 변수 중요도 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Boosting\n",
    "- 병렬적인 Bagging과 다르게 여러 개의 분류기가 순차적으로 학습 수행\n",
    "- 이전 학습에서 잘못 예측된 데이터에 가중치 부여해 반복적으로 학습하도록 -> 오차 보완\n",
    "\n",
    "장점) 지속적인 반복학습 통해 예측 어려운 영역 정확히 예측 가능<br>\n",
    "단점) 병렬 처리에 어려움 있고, 시간이 오래 소요됨, Overfitting 위험"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-1. AdaBoost\n",
    "- 가중치 부여한 약 분류기 모아 최종적인 강 분류기 생성\n",
    "- 랜덤 포레스트와 달리 분류기끼리의 중요도 고려"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2. Gradient Boost\n",
    "- 약분류기 결합한 강분류기 사용\n",
    "- 예측한 후 잔차를 새로운 Data로 두어 다시 예측 -> 점점 잔차 줄여나감"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "- Extreme Gradient Boosting\n",
    "- GBM을 병렬 학습이 지원되도록 구현해 수행시간 빠름\n",
    "- 과적합 규제 기능 존재\n",
    "- CART 앙상블 모델 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM\n",
    "- 균형 트리 분할 방식이 아닌 리프 중심 트리 분할\n",
    "- 최대 손실 값 가지는 리프 노드 지속적으로 분할\n",
    "- 예측 오류 손실 최소화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost\n",
    "- XGBoost처럼 Level-wise\n",
    "- 일부만 가지고 잔차 계산하고 모델 만든 뒤, 그 다음 데이터의 잔차는 이 모델로 예측한 값 사용"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
