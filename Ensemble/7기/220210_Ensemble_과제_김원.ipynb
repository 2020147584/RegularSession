{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvKRyZnGUl34"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkEcYi9kgZi9",
        "outputId": "ccd1ef55-4dff-4125-a97c-7f6f3f3ddc18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1Os9W36Ul39"
      },
      "outputs": [],
      "source": [
        "# Prepare dataset\n",
        "data = np.loadtxt('/content/drive/MyDrive/DSL/정규세션/220210 Ensemble/data.csv', delimiter=',', dtype=float)\n",
        "labels = data[:, 0]\n",
        "features = preprocessing.minmax_scale(data[:, 1:])\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels.ravel(), test_size=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3ihFCzOUl3-"
      },
      "source": [
        "### 의사결정나무\n",
        "* random_state = 2022 으로 설정\n",
        "* 변수명은 dt_clf 로 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhvoDFqWUl4B"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPo_jq5IUl4C"
      },
      "outputs": [],
      "source": [
        "# 빈 부분 코드 작성\n",
        "# decision tree\n",
        "dt_clf =DecisionTreeClassifier(random_state=2022)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-t-RQiDUl4D"
      },
      "outputs": [],
      "source": [
        "# 개별 분류기에 train set 피팅\n",
        "clf_1 = dt_clf.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EadDAXalUl4D"
      },
      "outputs": [],
      "source": [
        "# test셋으로 prediction\n",
        "dt_pred = clf_1.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuQ2MIEGUl4F",
        "outputId": "c369abb8-d772-4328-9731-6337b6b2936b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9207920792079208\n"
          ]
        }
      ],
      "source": [
        "# 성능 확인\n",
        "# accuracy_score 계산\n",
        "print(accuracy_score(y_test, dt_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNG1nHduUl4G"
      },
      "source": [
        "### 랜덤 포레스트\n",
        "* random_state = 2022\n",
        "* 변수명 rf_clf 로"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppEwM8aKUl4H"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abEGBQcMUl4I"
      },
      "outputs": [],
      "source": [
        "# random forest\n",
        "rf_clf = RandomForestClassifier(random_state=2022)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TY2agSdTUl4J"
      },
      "outputs": [],
      "source": [
        "# 개별 분류기에 train set 피팅\n",
        "clf_2 = rf_clf.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8pOW_2aUl4J"
      },
      "outputs": [],
      "source": [
        "# test셋으로 prediction\n",
        "rf_pred = clf_2.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qNPWeRbUl4K",
        "outputId": "2467506d-315e-4d89-ca32-218af610416f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9603960396039604\n"
          ]
        }
      ],
      "source": [
        "# 성능 확인\n",
        "# accuracy_score 계산\n",
        "print(accuracy_score(y_test,rf_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqO29h3DUl4K"
      },
      "source": [
        "### Gradient Boost\n",
        "* random_state = 2022\n",
        "* 변수명 gb_clf 로"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fwG9O4hUl4L"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBFBJ_4pUl4L"
      },
      "outputs": [],
      "source": [
        "# gradient boost\n",
        "gb_clf = GradientBoostingClassifier(random_state=2022)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQQCYCe9Ul4L"
      },
      "outputs": [],
      "source": [
        "# 개별 분류기에 train set 피팅\n",
        "clf_3 = gb_clf.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpEBDRYoUl4M"
      },
      "outputs": [],
      "source": [
        "# test셋으로 prediction\n",
        "gb_pred = clf_3.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Fk6L3rWUl4M",
        "outputId": "d2aa16a4-7e91-4bdc-b9a4-958b7c4de078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9603960396039604\n"
          ]
        }
      ],
      "source": [
        "# 성능 확인\n",
        "# accuracy_score 계산\n",
        "print(accuracy_score(y_test, gb_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZpkaEZTUl4N"
      },
      "source": [
        "### 보고서 과제\n",
        "1. voting, bagging, random forest, boosting, adaboost, gradient boost 의 특징 및 장단점을 스스로 정리해보기\n",
        "2. Boosting의 advanced model 인 XGBoost, LightGBM, CatBoost에 대해 찾아보고 정리해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# voting, bagging, random forest, boosting, adaboost, gradient boost 의 특징 및 장단점\n",
        "___\n",
        "\n",
        "## 1. voting \n",
        "###특징\n",
        "voting의 특징은 분류기가 여러개로, 다양한 모델에서 나온 예측 확률값을 평균을 내거나, 다수의 분류기에서 예측한 결과값을 결과로서 예측하는 방식을 따른다.   \n",
        "\n",
        "\n",
        "## 2. bagging\n",
        "###특징\n",
        "배깅은 Boostrap Aggregating의 약어로 boostrap이란 샘플을 의미한다. \n",
        "\n",
        "\n",
        "voting과 달리 데이터셋이 나눠져 있으며, 여러번 추출된 데이터 샘플을 통해서 각 모델에 학습시켜 그것을 합산해서 결과를 내놓는 방식이다.  \n",
        "\n",
        "###장단점 \n",
        "\n",
        "데이터셋을 복원추출로 뽑았기 때문에, 전체적인 데이터에 대한 자료를 다뤄지기 때문에 분산이 줄어들고, 과적합*overfitting*에 방지할 수 있다는 장점이 있다. \n",
        "\n",
        "\n",
        "## 3. random forest\n",
        "###특징\n",
        "decision tree 를 배깅을 활용한 모델로 *변수feature*를 임의추출한다는 특징이 있다. \n",
        "각 모델들의 노드들의 Information gain을 비교하여  변수의 중요도를 구할 수 있다.   \n",
        "\n",
        "###장단점 \n",
        "트리 안에서, 기준을 나누는 변수의 임의추출로 인해 변수의 다양성이 확보가 된다.\n",
        "tree안에서 모델에서 나누는 피처가 IG를 기준으로 선정이 되어 트리마다 같은 변수로 분류하게되기 때문에 모델의 다양성이 확보가 되지 않는 문제가 있다.\n",
        "\n",
        "  이를 변수의 임의추출을 통해서 트리의 다양성을 가지게 되며 모형들 끼리의 상관관계가 줄어들게 된다.\n",
        "\n",
        "\n",
        "\n",
        "## 4. boosting \n",
        "###특징\n",
        "여러개의 분류기가 순차적으로 (직렬로) 학습을 수행해 나간다. \n",
        "\n",
        "부족했던 점을 보완해서 가중치를 부여해서 오차를 줄여나가는 방식이다.\n",
        "잘못 분류된 데이터에는 다음에 변수에 가중치를 줘서 그 다음부터는 그 데이터에 집중해서 분류하게 된다. \n",
        "\n",
        "###장단점 \n",
        "\n",
        "\n",
        "병렬처리가 어렵고,  시간이 오래걸린다. \n",
        "\n",
        "\n",
        "## 5. gradient boost\n",
        "###특징\n",
        "약분류기를 합쳐서 강분류기로 만들어 사용하는데, 하나의 분류기에서 나온 잔차를 다시 다음 분류기로 넘겨서 잔차를 줄여나가는 방식을 한다.\n",
        "\n",
        "\n",
        "###장단점 \n",
        " \n",
        "시간이 오래 걸리며 성능은 좋아지겠지만 overfitting을 조심해야한다. \n",
        "---\n",
        "\n",
        "# Boosting의 advanced model\n",
        "\n",
        "## 1.  XGBoost\n",
        "\n",
        "### 개념 \n",
        "부스팅의 경우 단점으로 한 분류기가 학습을 한 후 다음 분류기로 넘겨주는 순차적인 진행으로 인해 과적합과 시간이 오래 걸리는 단점이 있다. \n",
        "\n",
        "이러한 문제점을 해결한 모델로 병렬처리를 구현하여서 학습과 분류에 있어서 시간이 빠르다는 장점이 있고,  과적합을 규제하는 기능이 탑재되어있다. \n",
        "이것을 파라미터로  learning_rate와 max_depth, 를 낮추고 min_child_weight과 gamma를 높여서 과적합을 방지할 수 있다.  \n",
        "\n",
        "```python\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 모델 선언\n",
        "model = xgb.XGBClassifier() \n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(x,y) \n",
        "\n",
        "# 모델 예측\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "#시각화\n",
        "import xgboost as xgb\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  # num_trees : 그림을 여러개 그릴시 그림 번호\n",
        "  # rankdir : 트리의 방향, 디폴트는 위아래 방향\n",
        "  # rankdir=\"LR\" : 왼쪽에서 오른쪽 방향으로 트리를 보여준다.\n",
        "  xgb.plot_tree(my_model, num_trees=0, rankdir='LR')\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(150, 100)\n",
        "\n",
        "  # 이미지 저장하고 싶다면\n",
        "  # fig.savefig('tree.png')\n",
        "\n",
        "  plt.show()\n",
        "```\n",
        "\n",
        "출처(https://wooono.tistory.com/97)\n",
        "\n",
        "## 2.  LightGBM\n",
        "\n",
        "일반의 Gradeint Boosting model 은 균형트리 분할이라는 방식을 이용하면서, 그 트리의 깊이를 최소화 하는 장점이 있다. 하지만 이러한 방식으로 트리를  생성할 경우, 과적합 문제에 대해서 강할 수 있찌만, 균형을 이루기 위한 시간이 많이 소요된다는 단점이 있다.\n",
        "\n",
        "Light GBM모델은 트리를 리프중심 잎을 중심으로 분할하여서 트리의 균형을 맞추는 것이 목표가 아닌 최대 손실값을 지니는 노드값을 지속적으로 분할하면서 트리가 깊어지게 된다. 이렇게 될경우 예측오류 손실이 최소화 된다는 장점이 있다. \n",
        "\n",
        "\n",
        "xgboost와 비교하여서 light gbm은 빠른 학습및 예측 수행시간을 가지며, 더 작은 메모리를 사용한다.하지만 리프중심의 분할은 depth가 매우 깊어지기 때문에 max_depth에 대한 파라미터 설정이 매우 중요하다. \n",
        "\n",
        "\n",
        "\n",
        "## 3.  CatBoost\n",
        "\n",
        "categorical feature를 처리하는데 중점을 둔 gradient boosting 기법으로, 범주형 데이터의 원핫인코딩 처리방식이 오버피팅되는 문제를 해결하기 위해서 관측치의 인덱스를 가지고 무작위의 순열을 만드는 것이다. 같은 변수를 재사용 하더라도, 피쳐들의 조합을 만들어내면 새로운 것으로 생각될 수 있다는 생각에서 나온 아이디어이다.\n",
        "\n",
        "\n",
        "이렇게 catboost는 여러가지 피쳐들의 조합을 만들기 때문에 시간이 굉장히 오래걸리지만 아주 좋은 예측선능을 보인다고 한다. \n"
      ],
      "metadata": {
        "id": "TSZDqa99jEFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f6vV5o-Ovw0R"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "220210 Ensemble 과제_김원.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}